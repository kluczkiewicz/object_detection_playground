{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d31c0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tensorflow as tf\n",
    "import os, glob\n",
    "from natsort import natsorted\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import cv2\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c375d5e6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba9a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37661f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('./labels.txt', header = None, names = ['id', 'class', 'x', 'y', 'w', 'h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3cd6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = labels[['class']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24113db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc643a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = []\n",
    "for x in labels_list:\n",
    "    #print(x[0])\n",
    "    y_list.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3bc61aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9a27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bb9747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Using 1600 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    \n",
    "    validation_split=0.2,\n",
    "    color_mode = 'grayscale',\n",
    "    shuffle = True,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df8a910a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Using 400 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    \n",
    "    color_mode = 'grayscale',\n",
    "    shuffle = True,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12d04ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "659d7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img, bbox):\n",
    "\n",
    "    _, x, y, w, h = bbox\n",
    "    \n",
    "    im = img.numpy().astype(\"uint8\")\n",
    "    \n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "    # Display the image\n",
    "    ax.imshow(im)\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d88f6fd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m         \u001b[43mdraw_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[148], line 3\u001b[0m, in \u001b[0;36mdraw_bbox\u001b[1;34m(img, bbox)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_bbox\u001b[39m(img, bbox):\n\u001b[1;32m----> 3\u001b[0m     _, x, y, w, h \u001b[38;5;241m=\u001b[39m bbox\n\u001b[0;32m      5\u001b[0m     im \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Create figure and axes\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        draw_bbox(images[i], labels_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff9e85c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 64, 64, 1)\n",
      "tf.Tensor([1 1 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1], shape=(32,), dtype=int32)\n",
      "(32, 64, 64, 1)\n",
      "tf.Tensor([0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 0 1 0], shape=(32,), dtype=int32)\n",
      "(2000, 6)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds.take(2):\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch)\n",
    "    \n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44e7384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48771407",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x),y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf5979",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d43635",
   "metadata": {},
   "source": [
    "#### IoU (Intersection over Union) metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "33eb5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(true, pred):\n",
    "    x1, y1, wt, ht = true\n",
    "    x3, y3, wp, hp = pred\n",
    "\n",
    "    x2 = x1 + wt\n",
    "    y2 = y1 + ht\n",
    "\n",
    "    x4 = x3 + wp\n",
    "    y4 = y3 + hp    \n",
    "    \n",
    "    x_inter1 = max(x1, x3)\n",
    "    y_inter1 = max(y1, y3)\n",
    "    x_inter2 = min(x2, x4)\n",
    "    y_inter2 = min(y2, y4)\n",
    "    \n",
    "    w_inter = x_inter2 - x_inter1\n",
    "    h_inter = y_inter2 - y_inter1\n",
    "    \n",
    "    area_inter = w_inter * h_inter\n",
    "    area_union = wt * ht + wp * hp - area_inter\n",
    "    \n",
    "    return area_inter / area_union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d870b0a0",
   "metadata": {},
   "source": [
    "# classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8073fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def printScores(model, X, Y):\n",
    "    print(\"Classification report:\")\n",
    "    model.predict(X)\n",
    "    print(classification_report(Y, np.argmax(model.predict(X), axis = 1)))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(Y, np.argmax(model.predict(X), axis = 1)))\n",
    "    print('Wrong predict:')\n",
    "    print(confusion_matrix(Y, np.argmax(model.predict(X), axis = 1)).sum() - confusion_matrix(Y, np.argmax(model.predict(X), axis = 1)).trace())\n",
    "    \n",
    "    \n",
    "def plotTrainingHistory(model):\n",
    "\n",
    "    fig, axes= plt.subplots(1,2,figsize=(10,5))\n",
    "    history = model.history\n",
    "    axes[0].plot(history['accuracy'])\n",
    "    axes[0].plot(history['val_accuracy'])\n",
    "    axes[0].set_ylabel('accuracy')\n",
    "    axes[0].set_xlabel('epoch')\n",
    "    axes[0].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "    axes[1].plot(history['loss'])\n",
    "    axes[1].plot(history['val_loss'])\n",
    "    axes[1].set_ylabel('loss')\n",
    "    axes[1].set_xlabel('epoch')\n",
    "    axes[1].legend(['train', 'validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "3bc09be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_class(nFilters, kernel_size, pool_size, nNeurons, nHiddenLayers, inputShape, outputWidth):\n",
    "    inputs = tf.keras.Input(shape=inputShape)\n",
    "    x = inputs\n",
    "    for iHidden in range(nHiddenLayers):   \n",
    "        #x = tf.keras.layers.Rescaling(1./255, input_shape=inputShape)\n",
    "        x = tf.keras.layers.Conv2D(nFilters, kernel_size=kernel_size)(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=pool_size)(x)\n",
    "        x = tf.keras.layers.Conv2D(nFilters, kernel_size=kernel_size)(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=pool_size)(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(nNeurons, activation=tf.nn.relu)(x)\n",
    "        x = tf.keras.layers.Dense(int(nNeurons / 2), activation=tf.nn.relu)(x)\n",
    "        x = tf.keras.layers.Dense(int(nNeurons / 2), activation=tf.nn.relu)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(outputWidth, activation=tf.nn.softmax)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca3cf57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 1)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "774470b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3db8e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 3s 39ms/step - loss: 0.6936 - accuracy: 0.4762 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 2s 33ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 2s 34ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 2s 33ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 2s 35ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.6932 - accuracy: 0.5025 - val_loss: 0.6933 - val_accuracy: 0.4900\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "feee0b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:12\u001b[0m\n",
      "File \u001b[1;32mD:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1xbr5ar4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"D:\\projekty\\mgr\\custom_nn\\mgr-env\\lib\\site-packages\\keras\\backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "batch_size = 32\n",
    "nFilters = 32\n",
    "kernel_size = 5\n",
    "pool_size = (5,5)\n",
    "nNeurons = 128 \n",
    "nHiddenLayers = 1 \n",
    "inputShape = (64, 64, 1)\n",
    "outputWidth = 2\n",
    "\n",
    "model = CNN_class(nFilters, kernel_size, pool_size, nNeurons, nHiddenLayers, inputShape, outputWidth)\n",
    "\n",
    "model_fit = model.fit(train_ds, validation_data = val_ds, epochs=5) \n",
    "plotTrainingHistory(model_fit)\n",
    "#printScores(model, X_test, np.argmax(Y_test, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dec90f",
   "metadata": {},
   "source": [
    "# localization model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8cd286",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4a4745d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_localization(nFilters, kernel_size, pool_size, nNeurons, nHiddenLayers, inputShape, outputWidth):\n",
    "    inputs = tf.keras.Input(shape=inputShape)\n",
    "    x = inputs  \n",
    "    x = tf.keras.layers.Conv2D(nFilters, (kernel_size, kernel_size), activation='relu', input_shape=inputShape)(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(nFilters, (kernel_size, kernel_size), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size)(x)\n",
    "    x = tf.keras.layers.Conv2D(nFilters, (kernel_size, kernel_size), activation='relu')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(int(nNeurons), activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(int(nNeurons / 2), activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(int(nNeurons / 4), activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(outputWidth)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss = tf.keras.losses.mse, optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0d842c",
   "metadata": {},
   "source": [
    "### model training v1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3a5bd32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "186/186 [==============================] - 86s 451ms/step - loss: 5414.4102 - val_loss: 2188.9612\n",
      "Epoch 2/30\n",
      "186/186 [==============================] - 77s 413ms/step - loss: 1920.0273 - val_loss: 1767.4860\n",
      "Epoch 3/30\n",
      "186/186 [==============================] - 76s 409ms/step - loss: 1321.0714 - val_loss: 1023.0104\n",
      "Epoch 4/30\n",
      "186/186 [==============================] - 78s 417ms/step - loss: 827.4633 - val_loss: 600.4661\n",
      "Epoch 5/30\n",
      "186/186 [==============================] - 76s 409ms/step - loss: 999.0931 - val_loss: 734.2000\n",
      "Epoch 6/30\n",
      "186/186 [==============================] - 78s 422ms/step - loss: 572.4796 - val_loss: 541.7265\n",
      "Epoch 7/30\n",
      "186/186 [==============================] - 75s 402ms/step - loss: 718.0910 - val_loss: 763.8120\n",
      "Epoch 8/30\n",
      "186/186 [==============================] - 74s 398ms/step - loss: 849.2565 - val_loss: 405.2641\n",
      "Epoch 9/30\n",
      "186/186 [==============================] - 74s 395ms/step - loss: 415.6583 - val_loss: 294.3798\n",
      "Epoch 10/30\n",
      "186/186 [==============================] - 74s 396ms/step - loss: 416.0832 - val_loss: 316.1682\n",
      "Epoch 11/30\n",
      "186/186 [==============================] - 74s 398ms/step - loss: 596.0375 - val_loss: 1388.3451\n",
      "Epoch 12/30\n",
      "186/186 [==============================] - 74s 399ms/step - loss: 665.9449 - val_loss: 1116.7633\n",
      "Epoch 13/30\n",
      "186/186 [==============================] - 74s 396ms/step - loss: 508.7553 - val_loss: 665.1854\n",
      "Epoch 14/30\n",
      "186/186 [==============================] - 74s 400ms/step - loss: 382.3089 - val_loss: 365.3456\n",
      "Epoch 15/30\n",
      "186/186 [==============================] - 74s 399ms/step - loss: 428.2922 - val_loss: 356.4874\n",
      "Epoch 16/30\n",
      "186/186 [==============================] - 74s 397ms/step - loss: 401.2086 - val_loss: 324.4859\n",
      "Epoch 17/30\n",
      "186/186 [==============================] - 75s 404ms/step - loss: 432.5982 - val_loss: 227.3724\n",
      "Epoch 18/30\n",
      "186/186 [==============================] - 75s 404ms/step - loss: 253.5554 - val_loss: 189.8240\n",
      "Epoch 19/30\n",
      "186/186 [==============================] - 77s 415ms/step - loss: 467.3489 - val_loss: 799.9091\n",
      "Epoch 20/30\n",
      "186/186 [==============================] - 76s 409ms/step - loss: 487.7652 - val_loss: 538.9437\n",
      "Epoch 21/30\n",
      "186/186 [==============================] - 78s 419ms/step - loss: 339.9234 - val_loss: 323.5399\n",
      "Epoch 22/30\n",
      "186/186 [==============================] - 75s 402ms/step - loss: 235.1887 - val_loss: 753.7518\n",
      "Epoch 23/30\n",
      "186/186 [==============================] - 74s 400ms/step - loss: 653.1654 - val_loss: 904.8000\n",
      "Epoch 24/30\n",
      "186/186 [==============================] - 74s 398ms/step - loss: 501.8096 - val_loss: 208.5526\n",
      "Epoch 25/30\n",
      "186/186 [==============================] - 75s 402ms/step - loss: 336.7672 - val_loss: 355.6830\n",
      "Epoch 26/30\n",
      "186/186 [==============================] - 75s 401ms/step - loss: 353.8584 - val_loss: 254.8722\n",
      "Epoch 27/30\n",
      "186/186 [==============================] - 74s 398ms/step - loss: 221.6512 - val_loss: 384.7963\n",
      "Epoch 28/30\n",
      "186/186 [==============================] - 76s 409ms/step - loss: 227.3413 - val_loss: 209.5684\n",
      "Epoch 29/30\n",
      "186/186 [==============================] - 75s 402ms/step - loss: 273.7625 - val_loss: 212.4311\n",
      "Epoch 30/30\n",
      "186/186 [==============================] - 75s 401ms/step - loss: 293.4136 - val_loss: 1128.5818\n",
      "CPU times: total: 7h 15min 26s\n",
      "Wall time: 38min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "batch_size = 32\n",
    "nFilters = 32\n",
    "kernel_size = 3\n",
    "pool_size = (5,5)\n",
    "nNeurons = 128 \n",
    "nHiddenLayers = 1 \n",
    "inputShape = (320, 320, 3)\n",
    "outputWidth = 4\n",
    "\n",
    "model = CNN_localization(nFilters, kernel_size, pool_size, nNeurons, nHiddenLayers, inputShape, outputWidth)\n",
    "model_fit = model.fit(X_train, Y_train, epochs=30, validation_split = 0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d4a39197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "n = 2500\n",
    "pred = model.predict(X_test[n:n+1])\n",
    "draw_bbox(X_test[n], Y_test[n], pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c00bba7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122.31591 , 118.56896 ,  60.966293,  70.17118 ], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4eb37137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img, true, pred = None):\n",
    "\n",
    "    xc, yc, w, h = true\n",
    "    \n",
    "    start = (int(xc - w / 2), int(yc - h/ 2))\n",
    "    end = (int(xc + w /2), int(yc + h / 2))\n",
    "    cv2.rectangle(img, start, end, (0,0,255))\n",
    "    if type(pred) != None:\n",
    "        xc, yc, w, h = pred\n",
    "        start = (int(xc - w / 2), int(yc - h/ 2))\n",
    "        end = (int(xc + w /2), int(yc + h / 2))\n",
    "        cv2.rectangle(img, start, end, (0,255,0))\n",
    "    \n",
    "    cv2.imshow('bbox', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fc7a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox(X_test[1200], Y_test[1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e86d35",
   "metadata": {},
   "source": [
    "### model training v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cacb3753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "186/186 [==============================] - 171s 908ms/step - loss: 5029.6265 - val_loss: 3043.1282\n",
      "Epoch 2/40\n",
      "186/186 [==============================] - 166s 891ms/step - loss: 2398.9636 - val_loss: 2468.6987\n",
      "Epoch 3/40\n",
      "186/186 [==============================] - 163s 879ms/step - loss: 1872.7931 - val_loss: 1594.8615\n",
      "Epoch 4/40\n",
      "186/186 [==============================] - 162s 869ms/step - loss: 1184.2799 - val_loss: 819.6199\n",
      "Epoch 5/40\n",
      "186/186 [==============================] - 164s 884ms/step - loss: 934.6226 - val_loss: 1082.6897\n",
      "Epoch 6/40\n",
      "186/186 [==============================] - 164s 883ms/step - loss: 1084.8322 - val_loss: 826.9205\n",
      "Epoch 7/40\n",
      "186/186 [==============================] - 164s 882ms/step - loss: 848.3145 - val_loss: 458.0546\n",
      "Epoch 8/40\n",
      "186/186 [==============================] - 164s 880ms/step - loss: 587.6010 - val_loss: 552.9735\n",
      "Epoch 9/40\n",
      "186/186 [==============================] - 163s 874ms/step - loss: 636.0518 - val_loss: 612.9821\n",
      "Epoch 10/40\n",
      "186/186 [==============================] - 164s 882ms/step - loss: 615.6001 - val_loss: 421.8234\n",
      "Epoch 11/40\n",
      "186/186 [==============================] - 163s 877ms/step - loss: 847.2058 - val_loss: 394.1106\n",
      "Epoch 12/40\n",
      "186/186 [==============================] - 164s 883ms/step - loss: 382.8678 - val_loss: 425.7082\n",
      "Epoch 13/40\n",
      "186/186 [==============================] - 163s 879ms/step - loss: 476.2368 - val_loss: 291.3391\n",
      "Epoch 14/40\n",
      "186/186 [==============================] - 164s 880ms/step - loss: 480.1907 - val_loss: 743.7501\n",
      "Epoch 15/40\n",
      "186/186 [==============================] - 164s 883ms/step - loss: 378.0292 - val_loss: 276.3658\n",
      "Epoch 16/40\n",
      "186/186 [==============================] - 164s 881ms/step - loss: 451.6679 - val_loss: 410.0138\n",
      "Epoch 17/40\n",
      "186/186 [==============================] - 164s 883ms/step - loss: 280.9244 - val_loss: 245.6883\n",
      "Epoch 18/40\n",
      "186/186 [==============================] - 164s 884ms/step - loss: 342.4588 - val_loss: 293.1809\n",
      "Epoch 19/40\n",
      "186/186 [==============================] - 164s 879ms/step - loss: 329.3462 - val_loss: 239.0979\n",
      "Epoch 20/40\n",
      "186/186 [==============================] - 166s 891ms/step - loss: 302.8047 - val_loss: 242.6257\n",
      "Epoch 21/40\n",
      "186/186 [==============================] - 165s 886ms/step - loss: 442.2645 - val_loss: 955.4086\n",
      "Epoch 22/40\n",
      "186/186 [==============================] - 163s 876ms/step - loss: 461.7537 - val_loss: 1119.1871\n",
      "Epoch 23/40\n",
      "186/186 [==============================] - 164s 881ms/step - loss: 441.5614 - val_loss: 216.3388\n",
      "Epoch 24/40\n",
      "186/186 [==============================] - 163s 876ms/step - loss: 253.0130 - val_loss: 198.7611\n",
      "Epoch 25/40\n",
      "186/186 [==============================] - 164s 880ms/step - loss: 257.2910 - val_loss: 298.6649\n",
      "Epoch 26/40\n",
      "186/186 [==============================] - 164s 884ms/step - loss: 296.2200 - val_loss: 220.9091\n",
      "Epoch 27/40\n",
      "186/186 [==============================] - 164s 883ms/step - loss: 319.3600 - val_loss: 262.6096\n",
      "Epoch 28/40\n",
      "186/186 [==============================] - 165s 888ms/step - loss: 219.9038 - val_loss: 264.5705\n",
      "Epoch 29/40\n",
      "186/186 [==============================] - 164s 881ms/step - loss: 289.4676 - val_loss: 181.3185\n",
      "Epoch 30/40\n",
      "186/186 [==============================] - 165s 885ms/step - loss: 183.0151 - val_loss: 211.7423\n",
      "Epoch 31/40\n",
      "186/186 [==============================] - 164s 882ms/step - loss: 243.4262 - val_loss: 156.1707\n",
      "Epoch 32/40\n",
      "186/186 [==============================] - 163s 874ms/step - loss: 171.1340 - val_loss: 132.4740\n",
      "Epoch 33/40\n",
      "186/186 [==============================] - 165s 885ms/step - loss: 205.0550 - val_loss: 104.9450\n",
      "Epoch 34/40\n",
      "186/186 [==============================] - 163s 877ms/step - loss: 130.3237 - val_loss: 109.7822\n",
      "Epoch 35/40\n",
      "186/186 [==============================] - 165s 886ms/step - loss: 117.7464 - val_loss: 118.1905\n",
      "Epoch 36/40\n",
      "186/186 [==============================] - 165s 889ms/step - loss: 134.8002 - val_loss: 146.2103\n",
      "Epoch 37/40\n",
      "186/186 [==============================] - 165s 885ms/step - loss: 117.1123 - val_loss: 118.4759\n",
      "Epoch 38/40\n",
      "186/186 [==============================] - 165s 886ms/step - loss: 132.2745 - val_loss: 210.9727\n",
      "Epoch 39/40\n",
      "186/186 [==============================] - 164s 880ms/step - loss: 200.2283 - val_loss: 182.7587\n",
      "Epoch 40/40\n",
      "186/186 [==============================] - 166s 893ms/step - loss: 152.4079 - val_loss: 103.0299\n",
      "CPU times: total: 20h 8min 47s\n",
      "Wall time: 1h 49min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "batch_size = 64\n",
    "nFilters = 32\n",
    "kernel_size = 5\n",
    "pool_size = (3,3)\n",
    "nNeurons = 128 \n",
    "nHiddenLayers = 1 \n",
    "inputShape = (320, 320, 3)\n",
    "outputWidth = 4\n",
    "\n",
    "model2 = CNN_localization(nFilters, kernel_size, pool_size, nNeurons, nHiddenLayers, inputShape, outputWidth)\n",
    "model2_fit = model2.fit(X_train, Y_train, epochs=40, validation_split = 0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "49ed2a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "pred = model2.predict(X_test[n:n+1])\n",
    "draw_bbox(X_test[n], Y_test[n], pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9cbdf455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iou_all = []\n",
    "errors = []\n",
    "for i in range(Y_test.shape[0]):\n",
    "    pred = model2.predict(X_test[i:i+1], verbose = 0)\n",
    "    result = iou(Y_test[i], pred[0])\n",
    "    if result <= 1:\n",
    "        iou_all.append(result)\n",
    "    else:\n",
    "        errors.append([i, result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "adf3ba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IoU < 1:  2894\n",
      "Mean IoU:  0.6193087811257244\n"
     ]
    }
   ],
   "source": [
    "print('Number of IoU < 1: ', len(iou_all))\n",
    "print('Mean IoU: ', np.mean(iou_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
